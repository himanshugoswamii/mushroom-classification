{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/Mushrooms(1).zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "print(\"✅ Extracted. Check the folder 'Mushrooms/' now.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOjmH9uthzcV",
        "outputId": "5e149962-09f0-45ed-d9a1-3cba18969e91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted. Check the folder 'Mushrooms/' now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "root_dir = '/content/Mushrooms'\n",
        "corrupted_files = []\n",
        "\n",
        "for subdir, _, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(subdir, file)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()\n",
        "        except (UnidentifiedImageError, IOError, OSError):\n",
        "            print(f\"❌ Corrupted: {file_path}\")\n",
        "            corrupted_files.append(file_path)\n",
        "\n",
        "for path in corrupted_files:\n",
        "    os.remove(path)\n",
        "\n",
        "print(f\"✅ Removed {len(corrupted_files)} corrupted files.\")\n"
      ],
      "metadata": {
        "id": "NJPD33GPhz9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec06f4c3-d16c-4a0f-afa2-5f93ebc9c304"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Corrupted: Mushrooms/.DS_Store\n",
            "✅ Removed 1 corrupted files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pickle\n",
        "\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 9\n"
      ],
      "metadata": {
        "id": "8wi4ir_gh1yz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data(train_dir):\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "    )\n",
        "    val_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "\n",
        "    with open(\"class_indices.pkl\", \"wb\") as f:\n",
        "        pickle.dump(train_generator.class_indices, f)\n",
        "\n",
        "    print(\"✅ Classes detected:\", train_generator.class_indices)\n",
        "    return train_generator, val_generator\n"
      ],
      "metadata": {
        "id": "kdNfpab0iGmR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(*IMAGE_SIZE, 3)),\n",
        "        layers.Conv2D(32, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "P7hBqx2BiInq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = 'Mushrooms'\n",
        "train_gen, val_gen = load_data(train_dir)\n",
        "\n",
        "model = build_model()\n",
        "model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS)\n",
        "\n",
        "model.save('softmax_model.keras')\n",
        "print(\"✅ Model saved as softmax_model.pkl\")\n"
      ],
      "metadata": {
        "id": "wSVdzY_TiK9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a974a39-bfb0-4e0e-b322-54f2166d5abd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5375 images belonging to 9 classes.\n",
            "Found 1339 images belonging to 9 classes.\n",
            "✅ Classes detected: {'Agaricus': 0, 'Amanita': 1, 'Boletus': 2, 'Cortinarius': 3, 'Entoloma': 4, 'Hygrocybe': 5, 'Lactarius': 6, 'Russula': 7, 'Suillus': 8}\n",
            "Epoch 1/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 179ms/step - accuracy: 0.2175 - loss: 2.0475 - val_accuracy: 0.3152 - val_loss: 1.8873\n",
            "Epoch 2/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 165ms/step - accuracy: 0.3407 - loss: 1.7933 - val_accuracy: 0.3376 - val_loss: 1.8641\n",
            "Epoch 3/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 169ms/step - accuracy: 0.4235 - loss: 1.6099 - val_accuracy: 0.3936 - val_loss: 1.7712\n",
            "Epoch 4/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 166ms/step - accuracy: 0.5258 - loss: 1.3626 - val_accuracy: 0.4287 - val_loss: 1.6933\n",
            "Epoch 5/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 165ms/step - accuracy: 0.6237 - loss: 1.0747 - val_accuracy: 0.3570 - val_loss: 2.0097\n",
            "Epoch 6/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 164ms/step - accuracy: 0.7472 - loss: 0.7369 - val_accuracy: 0.3958 - val_loss: 2.2361\n",
            "Epoch 7/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 166ms/step - accuracy: 0.8662 - loss: 0.4063 - val_accuracy: 0.3779 - val_loss: 2.6860\n",
            "Epoch 8/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 164ms/step - accuracy: 0.9246 - loss: 0.2412 - val_accuracy: 0.3697 - val_loss: 3.4212\n",
            "Epoch 9/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 162ms/step - accuracy: 0.9655 - loss: 0.1206 - val_accuracy: 0.3973 - val_loss: 3.9037\n",
            "Epoch 10/10\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 167ms/step - accuracy: 0.9824 - loss: 0.0686 - val_accuracy: 0.3831 - val_loss: 4.3160\n",
            "✅ Model saved as softmax_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kw9syVlOnUrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}